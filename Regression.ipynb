{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/domingues100/Water-Level-detection---IA/blob/main/Regressao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5savH5UHnplo"
      },
      "source": [
        "\n",
        "\n",
        "# Mounting o drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLdsXvwzniPF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6016bf-a5c7-411a-88bf-9dd0452e8ecf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0SOFOZGa8UD"
      },
      "source": [
        "Criar o resize do crop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QdY75_VZidB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os.path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gc\n",
        "from tensorflow import keras \n",
        "from keras.applications import ResNet50,ResNet101\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "from keras import applications\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from sklearn.model_selection import StratifiedKFold , KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import gc\n",
        "import csv\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Flatten\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib \n",
        "import glob\n",
        "from keras.models import load_model  \n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import statistics\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ipxcrFCbd5y"
      },
      "source": [
        "KFOLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSYJxkSDt5xT"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(path) #path to instances_default.csv\n",
        "Y = train_data[['label']]\n",
        "\n",
        "for ind in train_data.index:\n",
        "   train_data['label'][ind] = (train_data['label'][ind] - 3 ) #put the values between 0 and 4, instead of 3 and 7\n",
        "\n",
        "Y = train_data[['label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvKNAE3hgePW"
      },
      "outputs": [],
      "source": [
        "#directories\n",
        "image_dir = #path# #whithout the last /\n",
        "save_dir = #path# #with /\n",
        "val_dir = #path# #without the last /\n",
        "train_dir  =#path# #without the last /\n",
        "\n",
        "#stratitifiedKfold - but, to train, this isnt necessary, because folds were created before and used in all tests\n",
        "skf = StratifiedKFold(n_splits = 10, random_state = 7, shuffle = True) \n",
        "num_epochs = 150"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Image Data Generator"
      ],
      "metadata": {
        "id": "RfOA0hzqQ3Lm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKs__FKtu2Xc"
      },
      "outputs": [],
      "source": [
        "idg = ImageDataGenerator(width_shift_range=0.1,\n",
        "                         height_shift_range=0.1,\n",
        "                         zoom_range=0.3,\n",
        "                         fill_mode='nearest',\n",
        "                         horizontal_flip = True,\n",
        "                         rescale=1./255)\n",
        "\n",
        "def get_model_name(k):\n",
        "    return 'model_'+str(k)+'.h5'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creates lists and variables\n",
        "VALIDATION_ACCURACY = []\n",
        "VALIDATION_LOSS = []\n",
        "predicted = []\n",
        "validation_data1 = []\n",
        "scalers = []\n",
        "fold_var = 9\n",
        "n = Y.size"
      ],
      "metadata": {
        "id": "PRf-Ip7bB3-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YK9Up3WvC0S"
      },
      "outputs": [],
      "source": [
        "for train_index, val_index in skf.split(np.zeros(n),Y):\n",
        "\n",
        "  validation_data = pd.read_csv(val_dir+ str(fold_var)+\".csv\") #to get the folds that were used before\n",
        "  training_data = pd.read_csv(train_dir+ str(fold_var)+\".csv\") #to get the folds that were used before\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(training_data[\"label\"].to_numpy().reshape([-1,1]))\n",
        "\n",
        "  validation_data[\"normalizado\"] = scaler.transform(validation_data[\"label\"].to_numpy().reshape([-1,1]))\n",
        "  training_data[\"normalizado\"] = scaler.transform(training_data[\"label\"].to_numpy().reshape([-1,1]))\n",
        "\n",
        "  scalers.append(scaler)\n",
        "\n",
        "  validation_data1.append(validation_data)\n",
        "\n",
        "  training_data.to_csv(save_dir+\"training_data\"+str(fold_var)+\".csv\") #saves the folds used in the same directory, just per convinience\n",
        "  validation_data.to_csv(save_dir+\"validation_data\"+str(fold_var)+\".csv\") #saves the folds used in the same directory, just per convinience\n",
        "\n",
        "  train_data_generator = idg.flow_from_dataframe(training_data, directory = image_dir,\n",
        "\t\t\t\t\t\t       x_col = \"id\", y_col = \"normalizado\",\n",
        "\t\t\t\t\t\t       class_mode = \"raw\", shuffle = True)\n",
        " \n",
        "  valid_data_generator  = idg.flow_from_dataframe(validation_data, directory = image_dir,\n",
        "\t\t\t\t\t\t\tx_col = \"id\", y_col = \"normalizado\",\n",
        "\t\t\t\t\t\t\tclass_mode = \"raw\", shuffle = False) \n",
        "\n",
        "#model-------------------------------------------------------------------------------------------------------------------------------------------\n",
        "  model = keras.Sequential([\n",
        "      hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_50/classification/5\",\n",
        "                     output_shape=[1280], \n",
        "                     trainable=False), \n",
        "      keras.layers.Dropout(0.4),\n",
        "      keras.layers.Dense(1, activation='linear')])\n",
        "\n",
        "\n",
        "  model.build([None, 224, 224, 3])  \n",
        "    \n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "# -----------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "  model.compile(loss='mse', optimizer=optimizer, metrics=['mse', 'mae'])\n",
        "\t\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(fold_var), monitor='val_accuracy', verbose=1, save_best_only=False, mode='max') #save wheights\n",
        "  callbacks_list = [checkpoint]\n",
        "\n",
        "  history = model.fit(train_data_generator, epochs=num_epochs, callbacks=callbacks_list, validation_data=valid_data_generator)\n",
        "\n",
        "  model.load_weights(save_dir+\"model_\"+str(fold_var)+\".h5\") #load weights\n",
        "\t\n",
        "  joblib.dump(scaler, save_dir +\"scaler\"+str(fold_var)) #saves the standart scaler to use for predictions\n",
        "\n",
        "  tf.keras.backend.clear_session()\n",
        "\t\n",
        "  fold_var += 1\n",
        "  gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puHdnyVbB9Tb"
      },
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukeNCrE_kZJ0"
      },
      "source": [
        "Just need to run the next cell if it wasnt runned before. For example, if you just want to make predictions based on csvs, then run the directories cells and idg cell.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4lO63lBApM9"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "      hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_50/classification/5\",\n",
        "                     output_shape=[1280], \n",
        "                     trainable=False), \n",
        "      keras.layers.Dropout(0.4),\n",
        "      keras.layers.Dense(1, activation='linear')])\n",
        "\n",
        "model.build([None, 224, 224, 3])  \n",
        "    \n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "model.compile(loss='mse', optimizer=optimizer, metrics=['mse', 'mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXsJPZ4vABT2"
      },
      "outputs": [],
      "source": [
        "var = 1\n",
        "accuracy = []\n",
        "k=0\n",
        "\n",
        "for k in range(10):\n",
        "\n",
        "  validation_data = pd.read_csv(save_dir + f\"validation_data{k+1}.csv\") #get the same folds\n",
        "  scaler = joblib.load(save_dir +\"scaler\"+str(var)) #load scalers\n",
        "\n",
        "  valid_data_generator  = idg.flow_from_dataframe(validation_data, directory = image_dir,\n",
        "                x_col = \"id\", y_col = \"normalizado\",\n",
        "                class_mode = \"raw\", shuffle = False) \n",
        "\n",
        "  model.load_weights(save_dir+\"model_\"+str(var)+\".h5\") #load weights\n",
        "\n",
        "  pred = model.predict(valid_data_generator)\n",
        "  pred = scaler.inverse_transform(pred)\n",
        "  pred = np.squeeze(pred)\n",
        "\n",
        "  for itens in validation_data:\n",
        "    val_data = validation_data[\"label\"] .values.tolist()\n",
        "\n",
        "  val_data = list(map(int, val_data))  \n",
        "\n",
        "  k += 1\n",
        "\n",
        "  dados = {\"predicted_desnormalizado\": pred, \"labels\": val_data}\n",
        "  df = pd.DataFrame(dados)\n",
        "  df.to_csv(save_dir+f\"Resultados/df{k}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vnMF3Bdg7DV"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Di0OB0og-lu"
      },
      "outputs": [],
      "source": [
        "#gets the values of the predictions and calculates the errors\n",
        "\n",
        "erro = []\n",
        "erro2 = []\n",
        "erro3 = []\n",
        "\n",
        "for number in range(1,11):\n",
        "  dados = pd.read_csv(save_dir+f\"Resultados/df{k}.csv\")\n",
        "\n",
        "  for ind in dados.index:\n",
        "   dados['labels'][ind] = (dados['labels'][ind] + 3 ) #back the values to normal\n",
        "   dados['predicted_desnormalizado'][ind] = (dados['predicted_desnormalizado'][ind] + 3 ) #back the values to normal\n",
        "\n",
        "  predicted = dados[\"predicted_desnormalizado\"].tolist()\n",
        "  label = dados[\"labels\"].tolist()\n",
        "  erro.append(mean_absolute_error(predicted, label)) \n",
        "  erro2.append(mean_squared_error(predicted, label))\n",
        "  erro3.append(r2_score(predicted,label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzY3s90lLR_6"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(erro,columns = [\"EMA\"])\n",
        "df['EMQ'] = erro2\n",
        "df['r2'] = erro3\n",
        "iteracoes = [\"1\", '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
        "df[\"Iterações\"] = iteracoes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQx8KApMhjH3"
      },
      "outputs": [],
      "source": [
        "print(statistics.mean(erro))\n",
        "print(statistics.mean(erro2))\n",
        "print(statistics.mean(erro3))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "13G1buUF5XtfOQDP0nowrCystbwDp8ZzE",
      "authorship_tag": "ABX9TyONoAu6NfGC2tShbMEvqqeL",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
